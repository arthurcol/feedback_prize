{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8faeb506",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "98a35b48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T14:11:40.314000Z",
     "start_time": "2022-01-31T14:11:38.895271Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import csv\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "65d6673b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T15:38:59.349291Z",
     "start_time": "2022-01-31T15:38:59.345623Z"
    }
   },
   "outputs": [],
   "source": [
    "## Utilities variables\n",
    "\n",
    "#Sample mode \n",
    "SAMPLE_MODE = None\n",
    "\n",
    "#Max len of essay\n",
    "SEQ_LEN = 1024\n",
    "\n",
    "#Train, val, test split proportion\n",
    "VAL_SPLIT = 0.8\n",
    "TEST_SPLIT = 0.9\n",
    "\n",
    "#path\n",
    "PATH_RAW_DATA='/Users/arthurcollard/code/arthurcol/feedback_prize/raw_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68886c6f",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e37d4a9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T15:39:00.553896Z",
     "start_time": "2022-01-31T15:38:59.811761Z"
    }
   },
   "outputs": [],
   "source": [
    "#load data from csv file \n",
    "df = pd.read_csv(PATH_RAW_DATA+'train.csv',nrows=SAMPLE_MODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1398878",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a156bf65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T15:39:00.906473Z",
     "start_time": "2022-01-31T15:39:00.903007Z"
    }
   },
   "outputs": [],
   "source": [
    "## Def a function for labelling discourses per word\n",
    "\n",
    "def labelizer(label,len_,flag):\n",
    "    \"\"\"Repeat the label according to the length of the sentence. Makes use of B/I notation according to the position of the word within the sentence and the sentence within the essay.\n",
    "\n",
    "    Args:\n",
    "        label (str): NER label of the sentence.\n",
    "        len_ (int): Length of the sentence (n° of words).\n",
    "        flag (int): 1 if the sentence follows a sentence with the same label. 0 otherwise.\n",
    "\n",
    "    Returns:\n",
    "        str: Returns a string of length (n° of words) len_ with B/I-label repeated len_ times.\n",
    "    \"\"\"\n",
    "    if flag==0:\n",
    "        label_first = f'B-{label} '\n",
    "    else:\n",
    "        label_first = f'I-{label} '\n",
    "        \n",
    "    return (label_first + f'I-{label} '*(len_-1)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b8cac49f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T15:39:01.683728Z",
     "start_time": "2022-01-31T15:39:01.264699Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating features for labeling needs : \n",
    "\n",
    "    #Flag if the discourse is the same as the previous one\n",
    "df['previous_discourse_flag']=np.where(df['discourse_type'].shift(1)==df['discourse_type'],1,0)\n",
    "\n",
    "    #Get length of predictionstring\n",
    "df['predictionstring_len'] = df['predictionstring'].apply(lambda txt:len(txt.split()))\n",
    "\n",
    "    # Remove spaces in labels\n",
    "df['discourse_type']=df['discourse_type'].str.replace('Concluding Statement','Concluding_Statement')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "19479dfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T15:39:20.317850Z",
     "start_time": "2022-01-31T15:39:02.048456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>previous_discourse_flag</th>\n",
       "      <th>predictionstring_len</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>B-Lead I-Lead I-Lead I-Lead I-Lead I-Lead I-Le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \\\n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...   \n",
       "\n",
       "   previous_discourse_flag  predictionstring_len  \\\n",
       "0                        0                    44   \n",
       "\n",
       "                                               label  \n",
       "0  B-Lead I-Lead I-Lead I-Lead I-Lead I-Lead I-Le...  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize labelizer func and apply to our df \n",
    "labelizer_vect = np.vectorize(labelizer)\n",
    "df['label']=labelizer_vect(df['discourse_type'],df['predictionstring_len'],df['previous_discourse_flag'])\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4a361826",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T15:39:22.807043Z",
     "start_time": "2022-01-31T15:39:20.758887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[B-Position, I-Position, I-Position, I-Positio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00066EA9880D</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
       "      <td>[B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000E6DE9E817</td>\n",
       "      <td>[2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, ...</td>\n",
       "      <td>[B-Position, I-Position, I-Position, I-Positio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                   predictionstring  \\\n",
       "0  0000D23A521A  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "1  00066EA9880D  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2  000E6DE9E817  [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, ...   \n",
       "\n",
       "                                               label  \n",
       "0  [B-Position, I-Position, I-Position, I-Positio...  \n",
       "1  [B-Lead, I-Lead, I-Lead, I-Lead, I-Lead, I-Lea...  \n",
       "2  [B-Position, I-Position, I-Position, I-Positio...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Groupby ID to get predictionstrings and labels as a unique string\n",
    "\n",
    "df_essays = df.groupby('id').agg({'predictionstring':' '.join,'label':' '.join})\n",
    "\n",
    "## Transform into lists\n",
    "\n",
    "df_essays['label'] = df_essays['label'].apply(lambda txt : txt.split())\n",
    "df_essays['predictionstring'] = df_essays['predictionstring'].apply(lambda txt : txt.split())\n",
    "\n",
    "#remove utilities columns created in the original df\n",
    "df.drop(['previous_discourse_flag','predictionstring_len','label'],axis=1,inplace=True)\n",
    "\n",
    "#reset index\n",
    "df_essays.reset_index(inplace=True)\n",
    "\n",
    "display(df.head(3),df_essays.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a366065f",
   "metadata": {},
   "source": [
    "## Retrieve full text properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f34351d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T15:39:23.189304Z",
     "start_time": "2022-01-31T15:39:23.184054Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_essay(id_,mode='train'):\n",
    "    \"\"\"Function to get the full text of an essay from the .txt file.\n",
    "\n",
    "    Args:\n",
    "        id_ (str): id of the essay\n",
    "        mode (str, optional): determines whether to access *train* or *test* texts. \\\n",
    "        Defaults to 'train'.\n",
    "\n",
    "    Returns:\n",
    "        str: Returns the full text of the id\n",
    "    \"\"\"\n",
    "    with open(os.path.join(PATH_RAW_DATA,mode,f'{id_}.txt'),'r') as file:\n",
    "        txt = file.read()\n",
    "        return txt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999401a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54ac1c16",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8ea4c6b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T15:39:23.551445Z",
     "start_time": "2022-01-31T15:39:23.542505Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_labelize(essay,tokenizer,predictionstring=None,labels=None,max_len=SEQ_LEN):\n",
    "    \"\"\"Tokenize an essay and match each token with the corresponding label.\n",
    "\n",
    "    Args:\n",
    "        essay (str): Text to tokenize\n",
    "        tokenizer (tokenizer): Tokenizer from HF.\n",
    "        predictionstring (pandas.Series | numpy.array, optional): As a unique string, list of index position of words with a label. Must be provided with labels. Defaults to None.\n",
    "        labels (pandas.Series | numpy.array, optional): As a unique string, list of labels of each word. Must be provided with labels. Defaults to None.\n",
    "        max_len (int): Maximum sequence length for padding/truncating.\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        dict : Returns a dictionnary with input_ids,attention_mask and labels if passed.\n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = tokenizer(essay,\n",
    "                       return_attention_mask = True,\n",
    "                       return_token_type_ids = False,\n",
    "                       padding = 'max_length',\n",
    "                       max_length = SEQ_LEN,\n",
    "                       truncation = True,\n",
    "                       return_tensors='np'\n",
    "                      )\n",
    "    \n",
    "    word_ids=tokens.word_ids()\n",
    "    \n",
    "    labels_mapping = {'B-Lead' : 0,\n",
    "                  'B-Position' : 1,\n",
    "                  'B-Evidence' : 2,\n",
    "                  'B-Claim' : 3,\n",
    "                  'B-Concluding_Statement' : 4,\n",
    "                  'B-Counterclaim' : 5,\n",
    "                  'B-Rebuttal' : 6,\n",
    "                  'I-Lead' : 7,\n",
    "                  'I-Position' : 8,\n",
    "                  'I-Evidence' : 9,\n",
    "                  'I-Claim' : 10,\n",
    "                  'I-Concluding_Statement' : 11,\n",
    "                  'I-Counterclaim' : 12,\n",
    "                  'I-Rebuttal': 13}\n",
    "    \n",
    "    if labels:\n",
    "        match = {p:labels_mapping[l] for p,l in zip(predictionstring,labels)}\n",
    "        labels_matched = [-100 if (w==None or w==word_ids[i-1]) \\\n",
    "                            else match.get(str(w),14) \\\n",
    "                            for i,w in enumerate(word_ids)]\n",
    "                            \n",
    "        \n",
    "        return {\n",
    "        'input_ids' : tokens['input_ids'][0],\n",
    "        'attention_mask' : tokens['attention_mask'][0],\n",
    "        'labels': np.array(labels_matched)\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'input_ids' : tokens['input_ids'][0],\n",
    "        'attention_mask' : tokens['attention_mask'][0],\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c12b145",
   "metadata": {},
   "source": [
    "## Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3b7e8e0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T15:39:29.483547Z",
     "start_time": "2022-01-31T15:39:23.909848Z"
    }
   },
   "outputs": [],
   "source": [
    "## Instantiate tokenizer from HF\n",
    "tokenizer = AutoTokenizer.from_pretrained('allenai/longformer-base-4096')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "1e205fd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T15:39:29.885430Z",
     "start_time": "2022-01-31T15:39:29.882688Z"
    }
   },
   "outputs": [],
   "source": [
    "## vectorize the function \n",
    "tokenize_labelize_vect = np.vectorize(tokenize_labelize,excluded=['SEQ_LEN'],otypes=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "cb7f6971",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T15:41:34.034147Z",
     "start_time": "2022-01-31T15:40:57.147043Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0a760fb52842d891488ba65e4a4ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fetch essays text, per batch, save it in a csv file\n",
    "\n",
    "batch_size = 50\n",
    "nbatch = int(len(df_essays)/batch_size)+1\n",
    "\n",
    "fieldnames = ['id','predictionstring','label','essays']\n",
    "tokens = np.array([])\n",
    "\n",
    "with open(PATH_RAW_DATA+'preprocessed.csv','w') as file :\n",
    "    writer = csv.DictWriter(file,fieldnames = fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "for i in tqdm(range(nbatch+1)):\n",
    "    df_ = df_essays.loc[i*batch_size:(i+1)*batch_size-1].copy()\n",
    "    df_['essays'] = df_['id'].apply(get_essay)\n",
    "    tokens = np.append(tokens,tokenize_labelize_vect(df_.essays,tokenizer,\n",
    "                                           df_.predictionstring, df_.label ,max_len=SEQ_LEN))\n",
    "    df_.to_csv(PATH_RAW_DATA+'preprocessed.csv',mode='a',header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "632791cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T15:41:39.865470Z",
     "start_time": "2022-01-31T15:41:38.437574Z"
    }
   },
   "outputs": [],
   "source": [
    "ha = pd.read_csv(PATH_RAW_DATA+'preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b409336a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T15:41:40.524265Z",
     "start_time": "2022-01-31T15:41:40.513505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>label</th>\n",
       "      <th>essays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>['0', '1', '2', '3', '4', '5', '6', '7', '8', ...</td>\n",
       "      <td>['B-Position', 'I-Position', 'I-Position', 'I-...</td>\n",
       "      <td>Some people belive that the so called \"face\" o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00066EA9880D</td>\n",
       "      <td>['0', '1', '2', '3', '4', '5', '6', '7', '8', ...</td>\n",
       "      <td>['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...</td>\n",
       "      <td>Driverless cars are exaclty what you would exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000E6DE9E817</td>\n",
       "      <td>['2', '3', '4', '5', '6', '7', '8', '10', '11'...</td>\n",
       "      <td>['B-Position', 'I-Position', 'I-Position', 'I-...</td>\n",
       "      <td>Dear: Principal\\n\\nI am arguing against the po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001552828BD0</td>\n",
       "      <td>['0', '1', '2', '3', '4', '5', '6', '7', '8', ...</td>\n",
       "      <td>['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...</td>\n",
       "      <td>Would you be able to give your car up? Having ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>['0', '1', '2', '3', '4', '5', '6', '7', '8', ...</td>\n",
       "      <td>['B-Position', 'I-Position', 'I-Position', 'I-...</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15589</th>\n",
       "      <td>FFF1442D6698</td>\n",
       "      <td>['0', '1', '2', '3', '4', '5', '6', '7', '8', ...</td>\n",
       "      <td>['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...</td>\n",
       "      <td>Every student looks forward to summer break, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15590</th>\n",
       "      <td>FFF1ED4F8544</td>\n",
       "      <td>['0', '1', '2', '3', '4', '5', '6', '7', '8', ...</td>\n",
       "      <td>['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...</td>\n",
       "      <td>Many citizens argue that the Electoral college...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15591</th>\n",
       "      <td>FFF868E06176</td>\n",
       "      <td>['0', '1', '2', '3', '4', '5', '6', '7', '8', ...</td>\n",
       "      <td>['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...</td>\n",
       "      <td>Every summer break, students are given project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15592</th>\n",
       "      <td>FFFD0AF13501</td>\n",
       "      <td>['44', '45', '46', '47', '48', '49', '50', '51...</td>\n",
       "      <td>['B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', '...</td>\n",
       "      <td>In the article \"A Cowboy Who Rode the Waves\" L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15593</th>\n",
       "      <td>FFFF80B8CC2F</td>\n",
       "      <td>['0', '1', '2', '3', '4', '5', '6', '7', '8', ...</td>\n",
       "      <td>['B-Evidence', 'I-Evidence', 'I-Evidence', 'I-...</td>\n",
       "      <td>Venus is a planet what belong the System Solar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15594 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                   predictionstring  \\\n",
       "0      0000D23A521A  ['0', '1', '2', '3', '4', '5', '6', '7', '8', ...   \n",
       "1      00066EA9880D  ['0', '1', '2', '3', '4', '5', '6', '7', '8', ...   \n",
       "2      000E6DE9E817  ['2', '3', '4', '5', '6', '7', '8', '10', '11'...   \n",
       "3      001552828BD0  ['0', '1', '2', '3', '4', '5', '6', '7', '8', ...   \n",
       "4      0016926B079C  ['0', '1', '2', '3', '4', '5', '6', '7', '8', ...   \n",
       "...             ...                                                ...   \n",
       "15589  FFF1442D6698  ['0', '1', '2', '3', '4', '5', '6', '7', '8', ...   \n",
       "15590  FFF1ED4F8544  ['0', '1', '2', '3', '4', '5', '6', '7', '8', ...   \n",
       "15591  FFF868E06176  ['0', '1', '2', '3', '4', '5', '6', '7', '8', ...   \n",
       "15592  FFFD0AF13501  ['44', '45', '46', '47', '48', '49', '50', '51...   \n",
       "15593  FFFF80B8CC2F  ['0', '1', '2', '3', '4', '5', '6', '7', '8', ...   \n",
       "\n",
       "                                                   label  \\\n",
       "0      ['B-Position', 'I-Position', 'I-Position', 'I-...   \n",
       "1      ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...   \n",
       "2      ['B-Position', 'I-Position', 'I-Position', 'I-...   \n",
       "3      ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...   \n",
       "4      ['B-Position', 'I-Position', 'I-Position', 'I-...   \n",
       "...                                                  ...   \n",
       "15589  ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...   \n",
       "15590  ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...   \n",
       "15591  ['B-Lead', 'I-Lead', 'I-Lead', 'I-Lead', 'I-Le...   \n",
       "15592  ['B-Claim', 'I-Claim', 'I-Claim', 'I-Claim', '...   \n",
       "15593  ['B-Evidence', 'I-Evidence', 'I-Evidence', 'I-...   \n",
       "\n",
       "                                                  essays  \n",
       "0      Some people belive that the so called \"face\" o...  \n",
       "1      Driverless cars are exaclty what you would exp...  \n",
       "2      Dear: Principal\\n\\nI am arguing against the po...  \n",
       "3      Would you be able to give your car up? Having ...  \n",
       "4      I think that students would benefit from learn...  \n",
       "...                                                  ...  \n",
       "15589  Every student looks forward to summer break, i...  \n",
       "15590  Many citizens argue that the Electoral college...  \n",
       "15591  Every summer break, students are given project...  \n",
       "15592  In the article \"A Cowboy Who Rode the Waves\" L...  \n",
       "15593  Venus is a planet what belong the System Solar...  \n",
       "\n",
       "[15594 rows x 4 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "29bf0dfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T15:43:25.197688Z",
     "start_time": "2022-01-31T15:43:25.194279Z"
    }
   },
   "outputs": [],
   "source": [
    "## sanity check\n",
    "assert(tokens.shape[0]==ha.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d36d84",
   "metadata": {},
   "source": [
    "## Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "67bfb75e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T15:45:57.484070Z",
     "start_time": "2022-01-31T15:45:57.463250Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataset_creator(tokens,val_split=VAL_SPLIT,test_split=TEST_SPLIT):\n",
    "    \n",
    "    keys = tokens[0].keys()\n",
    "    \n",
    "    if 'labels' in keys:\n",
    "        \n",
    "        train_dict = {'input_ids':[],\n",
    "              'attention_mask':[]}\n",
    "        val_dict = {'input_ids':[],\n",
    "              'attention_mask':[]}\n",
    "        test_dict = {'input_ids':[],\n",
    "              'attention_mask':[]}\n",
    "        \n",
    "        train_labels = []\n",
    "        val_labels = []\n",
    "        test_labels = []\n",
    "    \n",
    "        idx_val=int(len(tokens)*VAL_SPLIT)\n",
    "        idx_test=int(len(tokens)*TEST_SPLIT)\n",
    "        \n",
    "        print('Creating training set...')\n",
    "        for t in tqdm(tokens[:idx_val]):\n",
    "            train_dict['input_ids'].append(t['input_ids'])\n",
    "            train_dict['attention_mask'].append(t['attention_mask'])\n",
    "            train_labels.append(t['labels'])\n",
    "        \n",
    "        print('Creating validation set...')\n",
    "        for t in tqdm(tokens[idx_val:idx_test]):\n",
    "            val_dict['input_ids'].append(t['input_ids'])\n",
    "            val_dict['attention_mask'].append(t['attention_mask'])\n",
    "            if 'labels' in keys:\n",
    "                val_labels.append(t['labels'])\n",
    "        \n",
    "        print('Creating testing set...')\n",
    "        for t in tqdm(tokens[idx_test:]):\n",
    "            test_dict['input_ids'].append(t['input_ids'])\n",
    "            test_dict['attention_mask'].append(t['attention_mask'])\n",
    "            if 'labels' in keys:\n",
    "                test_labels.append(t['labels'])\n",
    "\n",
    "        ## Converting lists into arrays \n",
    "        \n",
    "        for d in [train_dict,val_dict,test_dict]:\n",
    "            d['input_ids']=np.array(d['input_ids'])\n",
    "            d['attention_mask']=np.array(d['attention_mask'])\n",
    "            \n",
    "        ## WORKAROUND for now regarding -100 tokens to be excluded from the loss\n",
    "        train_labels=np.where(np.array(train_labels)==-100,15,np.array(train_labels))\n",
    "        val_labels=np.where(np.array(val_labels)==-100,15,np.array(val_labels))\n",
    "        test_labels=np.where(np.array(test_labels)==-100,15,np.array(test_labels))\n",
    "\n",
    "        #OHE labels\n",
    "        train_labels_ohe = np.zeros((len(train_labels),SEQ_LEN,16))\n",
    "        val_labels_ohe = np.zeros((len(val_labels),SEQ_LEN,16))\n",
    "        test_labels_ohe = np.zeros((len(test_labels),SEQ_LEN,16))\n",
    "\n",
    "        dim1_train = np.arange(len(train_labels))\n",
    "        dim1_val = np.arange(len(val_labels))\n",
    "        dim1_test = np.arange(len(test_labels))\n",
    "        dim2 = np.arange(SEQ_LEN)\n",
    "\n",
    "        train_labels_ohe[dim1_train[:,None,None],dim2[None,:,None],train_labels[:,:,None]] = 1\n",
    "        val_labels_ohe[dim1_val[:,None,None],dim2[None,:,None],val_labels[:,:,None]] = 1\n",
    "        test_labels_ohe[dim1_test[:,None,None],dim2[None,:,None],test_labels[:,:,None]] = 1\n",
    "    \n",
    "        return (train_dict,train_labels_ohe), (val_dict,val_labels_ohe), (test_dict,test_labels_ohe)\n",
    "    \n",
    "    data_dict = {'input_ids':[],\n",
    "              'attention_mask':[]}\n",
    "    \n",
    "    print('Creating new dataset...')\n",
    "    for t in tqdm_notebook(tokens):\n",
    "        data_dict['input_ids'].append(t['input_ids'])\n",
    "        data_dict['attention_mask'].append(t['attention_mask'])\n",
    "        \n",
    "    data_dict['input_ids'] = np.array(data_dict['input_ids'])\n",
    "    data_dict['attention_mask'] = np.array(data_dict['attention_mask'])\n",
    "    \n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "eb6d5831",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T15:46:00.233707Z",
     "start_time": "2022-01-31T15:45:58.397811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating training set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736a144e41204c9abe919f0ed6b69f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12475 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating validation set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702c6797fd27432ca5866126795bef3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1559 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating testing set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b78cac302c4b46b80b044b92af2a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1560 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train,val,test = dataset_creator(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e767d1",
   "metadata": {},
   "source": [
    "# Save datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2dbb8b1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T16:47:06.116490Z",
     "start_time": "2022-01-31T16:47:06.111606Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "595552d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T16:49:31.433530Z",
     "start_time": "2022-01-31T16:49:26.640034Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('../raw_data/train.pickle','wb') as file : \n",
    "    pickle.dump(train,file)\n",
    "\n",
    "with open('../raw_data/val.pickle','wb') as file : \n",
    "    pickle.dump(val,file)\n",
    "\n",
    "with open('../raw_data/test.pickle','wb') as file : \n",
    "    pickle.dump(test,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a88373bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-31T16:57:35.985823Z",
     "start_time": "2022-01-31T16:57:35.974710Z"
    }
   },
   "outputs": [],
   "source": [
    "### the end ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f4fad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
