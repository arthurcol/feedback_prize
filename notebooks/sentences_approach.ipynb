{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9879f5a0",
   "metadata": {},
   "source": [
    "# Imports and data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcd8c290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T18:07:54.341042Z",
     "start_time": "2022-02-18T18:07:46.242595Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import tensorflow as tf  \n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e58032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "\n",
    "LOAD_PREPROCESSED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29c02a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T18:08:22.700058Z",
     "start_time": "2022-02-18T18:08:21.842146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data, working on a sample\n",
    "df = pd.read_csv('../raw_data/train.csv')\n",
    "df['discourse_type']=df['discourse_type'].replace('Concluding Statement','Concluding_Statement') ## for later\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e24a0e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T18:08:29.289469Z",
     "start_time": "2022-02-18T18:08:29.285793Z"
    }
   },
   "outputs": [],
   "source": [
    "def is_not_sentence(text):\n",
    "    if '.' not in text[-5:] or not text[0].isupper():\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5838c6a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T18:08:30.380129Z",
     "start_time": "2022-02-18T18:08:30.282980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is approximatively 25.65% of discourses not limited by a sentence\n"
     ]
    }
   ],
   "source": [
    "## let's check the proportion of sentences\n",
    "df['is_not_sent']=df['discourse_text'].apply(is_not_sentence)\n",
    "p = df['is_not_sent'].sum()/2/len(df)\n",
    "print(f\"There is approximatively {p*100:.2f}% of discourses not limited by a sentence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b6ec78",
   "metadata": {},
   "source": [
    "# Preprocess the data\n",
    "\n",
    "Objective = get the data at sentence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "174e003e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T18:54:27.958678Z",
     "start_time": "2022-02-18T18:54:27.955892Z"
    }
   },
   "outputs": [],
   "source": [
    "#Pseudo code : \n",
    "# 1- create a match predictionstring-label-word\n",
    "    # a) repeat label\n",
    "    # b) groupby id / join \n",
    "    # c) match id/full text\n",
    "    \n",
    "# 2- go the other way around : from full text / ps / label to sentences / ps / label \n",
    "    # a) get the indice of the end of a sentence ; explode our dataset\n",
    "    # b) split by this indice for ps and labels\n",
    "    \n",
    "# 3- choose a type for sentences with 2 types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c9996fda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T18:54:28.368944Z",
     "start_time": "2022-02-18T18:54:28.363677Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_essay(id_,mode='train'):\n",
    "    \"\"\"Function to get the full text of an essay from the .txt file.\n",
    "\n",
    "    Args:\n",
    "        id_ (str): id of the essay\n",
    "        mode (str, optional): determines whether to access *train* or *test* texts. \\\n",
    "        Defaults to 'train'.\n",
    "\n",
    "    Returns:\n",
    "        str: Returns the full text of the id\n",
    "    \"\"\"\n",
    "    with open(os.path.join('../raw_data',mode,f'{id_}.txt'),'r') as file:\n",
    "        txt = file.read()\n",
    "    return txt.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ce756996",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T18:54:48.257073Z",
     "start_time": "2022-02-18T18:54:28.692849Z"
    }
   },
   "outputs": [],
   "source": [
    "def repeater(label,txt):\n",
    "    \"\"\"\n",
    "    Repeat discourse_type * length of discourse\n",
    "    \"\"\"\n",
    "    words=[]\n",
    "    labels=[]\n",
    "    for w in txt.split():\n",
    "        if '.' in w[-2:]:\n",
    "            labels.append(label+'.')\n",
    "        else:\n",
    "            labels.append(label)\n",
    "    return ' '.join(labels)\n",
    "\n",
    "repeater_vect = np.vectorize(repeater) #vectorize our function\n",
    "\n",
    "df['labels'] = repeater_vect(df['discourse_type'],df['discourse_text']) #apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "adf20f60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T18:54:48.377930Z",
     "start_time": "2022-02-18T18:54:48.362783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>is_not_sent</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "      <td>1</td>\n",
       "      <td>Lead Lead Lead Lead Lead Lead Lead Lead. Lead ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  \\\n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...   \n",
       "\n",
       "   is_not_sent                                             labels  \n",
       "0            1  Lead Lead Lead Lead Lead Lead Lead Lead. Lead ...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4c0a1589",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T18:54:48.974562Z",
     "start_time": "2022-02-18T18:54:48.535815Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>Position Position Position Position Position P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                   predictionstring  \\\n",
       "0  0000D23A521A  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...   \n",
       "\n",
       "                                              labels  \n",
       "0  Position Position Position Position Position P...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#recreate dataset at essay level \n",
    "df_essay=df.groupby('id').agg({'predictionstring':' '.join,'labels':' '.join}).reset_index()\n",
    "df_essay.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bbd97e49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T18:55:08.889909Z",
     "start_time": "2022-02-18T18:55:06.198324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>Position Position Position Position Position P...</td>\n",
       "      <td>Some people belive that the so called \"face\" o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00066EA9880D</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>Lead Lead Lead Lead Lead Lead Lead Lead Lead L...</td>\n",
       "      <td>Driverless cars are exaclty what you would exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000E6DE9E817</td>\n",
       "      <td>2 3 4 5 6 7 8 10 11 12 13 14 15 16 17 18 19 20...</td>\n",
       "      <td>Position Position Position Position Position P...</td>\n",
       "      <td>Dear: Principal\\n\\nI am arguing against the po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                   predictionstring  \\\n",
       "0  0000D23A521A  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...   \n",
       "1  00066EA9880D  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...   \n",
       "2  000E6DE9E817  2 3 4 5 6 7 8 10 11 12 13 14 15 16 17 18 19 20...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  Position Position Position Position Position P...   \n",
       "1  Lead Lead Lead Lead Lead Lead Lead Lead Lead L...   \n",
       "2  Position Position Position Position Position P...   \n",
       "\n",
       "                                                text  \n",
       "0  Some people belive that the so called \"face\" o...  \n",
       "1  Driverless cars are exaclty what you would exp...  \n",
       "2  Dear: Principal\\n\\nI am arguing against the po...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrieve full text\n",
    "df_essay['text']=df_essay['id'].apply(get_essay) #get essay full text for each id\n",
    "assert(df_essay.shape[0]==15594) #check\n",
    "df_essay.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1ee92c37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T18:56:51.683054Z",
     "start_time": "2022-02-18T18:56:50.380497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>idx_last_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>Position Position Position Position Position P...</td>\n",
       "      <td>Some people belive that the so called \"face\" o...</td>\n",
       "      <td>[15, 20, 33, 50, 68, 83, 116, 133, 139, 153, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00066EA9880D</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>Lead Lead Lead Lead Lead Lead Lead Lead Lead L...</td>\n",
       "      <td>Driverless cars are exaclty what you would exp...</td>\n",
       "      <td>[10, 27, 47, 62, 76, 97, 123, 153, 169, 194, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000E6DE9E817</td>\n",
       "      <td>2 3 4 5 6 7 8 10 11 12 13 14 15 16 17 18 19 20...</td>\n",
       "      <td>Position Position Position Position Position P...</td>\n",
       "      <td>Dear: Principal\\n\\nI am arguing against the po...</td>\n",
       "      <td>[53, 72, 80, 114, 136, 171, 212, 241, 265, 271...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                   predictionstring  \\\n",
       "0  0000D23A521A  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...   \n",
       "1  00066EA9880D  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...   \n",
       "2  000E6DE9E817  2 3 4 5 6 7 8 10 11 12 13 14 15 16 17 18 19 20...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  Position Position Position Position Position P...   \n",
       "1  Lead Lead Lead Lead Lead Lead Lead Lead Lead L...   \n",
       "2  Position Position Position Position Position P...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Some people belive that the so called \"face\" o...   \n",
       "1  Driverless cars are exaclty what you would exp...   \n",
       "2  Dear: Principal\\n\\nI am arguing against the po...   \n",
       "\n",
       "                                       idx_last_word  \n",
       "0  [15, 20, 33, 50, 68, 83, 116, 133, 139, 153, 1...  \n",
       "1  [10, 27, 47, 62, 76, 97, 123, 153, 169, 194, 2...  \n",
       "2  [53, 72, 80, 114, 136, 171, 212, 241, 265, 271...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the indices of the last word of a sentence, meaning position of all the words followed by a '.'\n",
    "df_essay['idx_last_word']=df_essay['text'].apply(lambda text : [i for i, w in enumerate(text.split()) if '.' in w[-2:]])\n",
    "df_essay.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9e62bc53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:02:14.291301Z",
     "start_time": "2022-02-18T19:02:13.905503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313505, 5)\n",
      "(313494, 5)\n"
     ]
    }
   ],
   "source": [
    "## 1- explode the dataset on column indices\n",
    "df_essay = df_essay.explode('idx_last_word')\n",
    "\n",
    "# /!\\We have 11 strange essays wandering around without any punctuation : ciao /!\\\n",
    "print(df_essay.shape)\n",
    "df_essay.dropna(axis=0,how='any',inplace=True)\n",
    "print(df_essay.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "73057e12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:03:03.342554Z",
     "start_time": "2022-02-18T19:03:03.329849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "      <th>idx_last_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>Position Position Position Position Position P...</td>\n",
       "      <td>Some people belive that the so called \"face\" o...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>Position Position Position Position Position P...</td>\n",
       "      <td>Some people belive that the so called \"face\" o...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>Position Position Position Position Position P...</td>\n",
       "      <td>Some people belive that the so called \"face\" o...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>Position Position Position Position Position P...</td>\n",
       "      <td>Some people belive that the so called \"face\" o...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>Position Position Position Position Position P...</td>\n",
       "      <td>Some people belive that the so called \"face\" o...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15593</th>\n",
       "      <td>FFFF80B8CC2F</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>Evidence Evidence Evidence Evidence Evidence E...</td>\n",
       "      <td>Venus is a planet what belong the System Solar...</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15593</th>\n",
       "      <td>FFFF80B8CC2F</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>Evidence Evidence Evidence Evidence Evidence E...</td>\n",
       "      <td>Venus is a planet what belong the System Solar...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15593</th>\n",
       "      <td>FFFF80B8CC2F</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>Evidence Evidence Evidence Evidence Evidence E...</td>\n",
       "      <td>Venus is a planet what belong the System Solar...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15593</th>\n",
       "      <td>FFFF80B8CC2F</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>Evidence Evidence Evidence Evidence Evidence E...</td>\n",
       "      <td>Venus is a planet what belong the System Solar...</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15593</th>\n",
       "      <td>FFFF80B8CC2F</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...</td>\n",
       "      <td>Evidence Evidence Evidence Evidence Evidence E...</td>\n",
       "      <td>Venus is a planet what belong the System Solar...</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313494 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                   predictionstring  \\\n",
       "0      0000D23A521A  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...   \n",
       "0      0000D23A521A  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...   \n",
       "0      0000D23A521A  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...   \n",
       "0      0000D23A521A  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...   \n",
       "0      0000D23A521A  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...   \n",
       "...             ...                                                ...   \n",
       "15593  FFFF80B8CC2F  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...   \n",
       "15593  FFFF80B8CC2F  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...   \n",
       "15593  FFFF80B8CC2F  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...   \n",
       "15593  FFFF80B8CC2F  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...   \n",
       "15593  FFFF80B8CC2F  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18...   \n",
       "\n",
       "                                                  labels  \\\n",
       "0      Position Position Position Position Position P...   \n",
       "0      Position Position Position Position Position P...   \n",
       "0      Position Position Position Position Position P...   \n",
       "0      Position Position Position Position Position P...   \n",
       "0      Position Position Position Position Position P...   \n",
       "...                                                  ...   \n",
       "15593  Evidence Evidence Evidence Evidence Evidence E...   \n",
       "15593  Evidence Evidence Evidence Evidence Evidence E...   \n",
       "15593  Evidence Evidence Evidence Evidence Evidence E...   \n",
       "15593  Evidence Evidence Evidence Evidence Evidence E...   \n",
       "15593  Evidence Evidence Evidence Evidence Evidence E...   \n",
       "\n",
       "                                                    text idx_last_word  \n",
       "0      Some people belive that the so called \"face\" o...            15  \n",
       "0      Some people belive that the so called \"face\" o...            20  \n",
       "0      Some people belive that the so called \"face\" o...            33  \n",
       "0      Some people belive that the so called \"face\" o...            50  \n",
       "0      Some people belive that the so called \"face\" o...            68  \n",
       "...                                                  ...           ...  \n",
       "15593  Venus is a planet what belong the System Solar...            79  \n",
       "15593  Venus is a planet what belong the System Solar...            97  \n",
       "15593  Venus is a planet what belong the System Solar...           140  \n",
       "15593  Venus is a planet what belong the System Solar...           156  \n",
       "15593  Venus is a planet what belong the System Solar...           167  \n",
       "\n",
       "[313494 rows x 5 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e4004d14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:04:15.863320Z",
     "start_time": "2022-02-18T19:04:15.734293Z"
    }
   },
   "outputs": [],
   "source": [
    "## 2- create 'artificially' an 'idx_first_word' column by shifting idx_last_word col\n",
    "## /!\\ We will not add nor subtract at this point to avoid confusion /!\\\n",
    "\n",
    "\n",
    "\n",
    "df_essay['idx_first_word'] = df_essay.groupby('id')['idx_last_word'].shift(1) ## We shift per essay !\n",
    "\n",
    "df_essay['idx_first_word'].fillna(0,inplace=True) #replace NaN with 0 as it is the first word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0ed63cc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:04:17.734890Z",
     "start_time": "2022-02-18T19:04:17.730187Z"
    }
   },
   "outputs": [],
   "source": [
    "## objective now = split ps, labels and text according to idx_first_word and idx_last_word \n",
    "\n",
    "def slicer(text,idx_first_word,idx_last_word):\n",
    "    text = text.split()\n",
    "    if idx_first_word==0:\n",
    "        return ' '.join(text[:idx_last_word+1])\n",
    "    return ' '.join(text[idx_first_word+1:idx_last_word+1])\n",
    "    \n",
    "slicer_vect=np.vectorize(slicer) #vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0e9b835f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:06:55.354370Z",
     "start_time": "2022-02-18T19:06:55.326683Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## type issue \n",
    "df_essay['idx_last_word']=df_essay['idx_last_word'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "89ee2368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:09:27.162857Z",
     "start_time": "2022-02-18T19:08:14.275056Z"
    }
   },
   "outputs": [],
   "source": [
    "#apply our magical slicer \n",
    "\n",
    "df_essay['sentence']=slicer_vect(df_essay['text'],df_essay['idx_first_word'],df_essay['idx_last_word'])\n",
    "df_essay['ps']=slicer_vect(df_essay['predictionstring'],df_essay['idx_first_word'],df_essay['idx_last_word'])\n",
    "df_essay['type']=slicer_vect(df_essay['labels'],df_essay['idx_first_word'],df_essay['idx_last_word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b6a4f2fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:10:19.528330Z",
     "start_time": "2022-02-18T19:10:18.819638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>ps</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Some people belive that the so called \"face\" o...</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15</td>\n",
       "      <td>Position Position Position Position Position P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>This is not the case.</td>\n",
       "      <td>16 17 18 19 20</td>\n",
       "      <td>Position Position Position Position Position.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>The face on Mars is a naturally occuring land ...</td>\n",
       "      <td>21 22 23 24 25 26 27 28 29 30 31 32 33</td>\n",
       "      <td>Position Position Position Position Position P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>It was not created by aliens, and there is no ...</td>\n",
       "      <td>34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 4...</td>\n",
       "      <td>Evidence Evidence Evidence Evidence Evidence E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>There is no evidence that NASA has found that ...</td>\n",
       "      <td>51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 6...</td>\n",
       "      <td>Evidence Evidence Evidence Evidence Evidence E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                           sentence  \\\n",
       "0  0000D23A521A  Some people belive that the so called \"face\" o...   \n",
       "1  0000D23A521A                              This is not the case.   \n",
       "2  0000D23A521A  The face on Mars is a naturally occuring land ...   \n",
       "3  0000D23A521A  It was not created by aliens, and there is no ...   \n",
       "4  0000D23A521A  There is no evidence that NASA has found that ...   \n",
       "\n",
       "                                                  ps  \\\n",
       "0              0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15   \n",
       "1                                     16 17 18 19 20   \n",
       "2             21 22 23 24 25 26 27 28 29 30 31 32 33   \n",
       "3  34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 4...   \n",
       "4  51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 6...   \n",
       "\n",
       "                                                type  \n",
       "0  Position Position Position Position Position P...  \n",
       "1      Position Position Position Position Position.  \n",
       "2  Position Position Position Position Position P...  \n",
       "3  Evidence Evidence Evidence Evidence Evidence E...  \n",
       "4  Evidence Evidence Evidence Evidence Evidence E...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now we can have a clean dataset\n",
    "df_essay.reset_index(inplace=True,drop=True)\n",
    "df_preproc = df_essay.drop(['predictionstring','labels','text','idx_first_word','idx_last_word'],axis=1)\n",
    "df_preproc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e64a76",
   "metadata": {},
   "source": [
    "## Let's attribute a single discourse type per sentence\n",
    "\n",
    "We'll also check our initial assumption by looking at initial % of sentences of each type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b0b59f36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:13:54.419521Z",
     "start_time": "2022-02-18T19:13:52.454165Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preproc['type_len']=df_preproc['type'].apply(lambda txt:Counter(txt.replace('.','').split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "4aa342bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T21:18:13.320164Z",
     "start_time": "2022-02-20T21:18:13.313509Z"
    }
   },
   "outputs": [],
   "source": [
    "## create a function\n",
    "def length_checker(dict_):\n",
    "    #if len(dict_.keys())==1:\n",
    "     #   return 1\n",
    "    try: #len(dict_.keys())==2:\n",
    "        return max(dict_.values())/sum(dict_.values())\n",
    "    except:\n",
    "        return 'Coucou'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "a3bb6c3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T21:18:24.316356Z",
     "start_time": "2022-02-20T21:18:24.118666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>ps</th>\n",
       "      <th>type</th>\n",
       "      <th>type_len</th>\n",
       "      <th>type_prop</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Some people belive that the so called \"face\" o...</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15</td>\n",
       "      <td>Position Position Position Position Position P...</td>\n",
       "      <td>{'Position': 16}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>This is not the case.</td>\n",
       "      <td>16 17 18 19 20</td>\n",
       "      <td>Position Position Position Position Position.</td>\n",
       "      <td>{'Position': 5}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>The face on Mars is a naturally occuring land ...</td>\n",
       "      <td>21 22 23 24 25 26 27 28 29 30 31 32 33</td>\n",
       "      <td>Position Position Position Position Position P...</td>\n",
       "      <td>{'Position': 13}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>It was not created by aliens, and there is no ...</td>\n",
       "      <td>34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 4...</td>\n",
       "      <td>Evidence Evidence Evidence Evidence Evidence E...</td>\n",
       "      <td>{'Evidence': 17}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>There is no evidence that NASA has found that ...</td>\n",
       "      <td>51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 6...</td>\n",
       "      <td>Evidence Evidence Evidence Evidence Evidence E...</td>\n",
       "      <td>{'Evidence': 18}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Evidence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                           sentence  \\\n",
       "0  0000D23A521A  Some people belive that the so called \"face\" o...   \n",
       "1  0000D23A521A                              This is not the case.   \n",
       "2  0000D23A521A  The face on Mars is a naturally occuring land ...   \n",
       "3  0000D23A521A  It was not created by aliens, and there is no ...   \n",
       "4  0000D23A521A  There is no evidence that NASA has found that ...   \n",
       "\n",
       "                                                  ps  \\\n",
       "0              0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15   \n",
       "1                                     16 17 18 19 20   \n",
       "2             21 22 23 24 25 26 27 28 29 30 31 32 33   \n",
       "3  34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 4...   \n",
       "4  51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 6...   \n",
       "\n",
       "                                                type          type_len  \\\n",
       "0  Position Position Position Position Position P...  {'Position': 16}   \n",
       "1      Position Position Position Position Position.   {'Position': 5}   \n",
       "2  Position Position Position Position Position P...  {'Position': 13}   \n",
       "3  Evidence Evidence Evidence Evidence Evidence E...  {'Evidence': 17}   \n",
       "4  Evidence Evidence Evidence Evidence Evidence E...  {'Evidence': 18}   \n",
       "\n",
       "  type_prop     label  \n",
       "0       1.0  Position  \n",
       "1       1.0  Position  \n",
       "2       1.0  Position  \n",
       "3       1.0  Evidence  \n",
       "4       1.0  Evidence  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preproc['type_prop']=df_preproc['type_len'].apply(length_checker)\n",
    "df_preproc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "01d4f4e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T21:18:49.553402Z",
     "start_time": "2022-02-20T21:18:49.259171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>ps</th>\n",
       "      <th>type</th>\n",
       "      <th>type_len</th>\n",
       "      <th>type_prop</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>00066EA9880D</td>\n",
       "      <td>Becuase of all of these problems that arise wi...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>Coucou</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>000E6DE9E817</td>\n",
       "      <td>I am against this policy change.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>Coucou</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>000E6DE9E817</td>\n",
       "      <td>Sincerely, Student.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>Coucou</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0027FC00C35B</td>\n",
       "      <td>Now back to the questions.</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>Coucou</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0027FC00C35B</td>\n",
       "      <td>Are you willing to get on this phone while dri...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>Coucou</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313398</th>\n",
       "      <td>FFE4B98E0B1E</td>\n",
       "      <td>By designing their own projects students can g...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>Coucou</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313434</th>\n",
       "      <td>FFF1442D6698</td>\n",
       "      <td>Students don't like doing work during the summ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>Coucou</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313470</th>\n",
       "      <td>FFF868E06176</td>\n",
       "      <td>The summer break projects created by the stude...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>Coucou</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313482</th>\n",
       "      <td>FFFD0AF13501</td>\n",
       "      <td>You can go so many places and you rarely go to...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>Coucou</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313483</th>\n",
       "      <td>FFFD0AF13501</td>\n",
       "      <td>It sounds so cool and you never know where you...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>{}</td>\n",
       "      <td>Coucou</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12664 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                           sentence ps  \\\n",
       "41      00066EA9880D  Becuase of all of these problems that arise wi...      \n",
       "51      000E6DE9E817                   I am against this policy change.      \n",
       "52      000E6DE9E817                                Sincerely, Student.      \n",
       "243     0027FC00C35B                         Now back to the questions.      \n",
       "244     0027FC00C35B  Are you willing to get on this phone while dri...      \n",
       "...              ...                                                ... ..   \n",
       "313398  FFE4B98E0B1E  By designing their own projects students can g...      \n",
       "313434  FFF1442D6698  Students don't like doing work during the summ...      \n",
       "313470  FFF868E06176  The summer break projects created by the stude...      \n",
       "313482  FFFD0AF13501  You can go so many places and you rarely go to...      \n",
       "313483  FFFD0AF13501  It sounds so cool and you never know where you...      \n",
       "\n",
       "       type type_len type_prop label  \n",
       "41                {}    Coucou  None  \n",
       "51                {}    Coucou  None  \n",
       "52                {}    Coucou  None  \n",
       "243               {}    Coucou  None  \n",
       "244               {}    Coucou  None  \n",
       "...     ...      ...       ...   ...  \n",
       "313398            {}    Coucou  None  \n",
       "313434            {}    Coucou  None  \n",
       "313470            {}    Coucou  None  \n",
       "313482            {}    Coucou  None  \n",
       "313483            {}    Coucou  None  \n",
       "\n",
       "[12664 rows x 7 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preproc[(df_preproc.type_prop == 'Coucou')].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f65a8269",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:22:12.206154Z",
     "start_time": "2022-02-18T19:22:12.028728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 17.64% of sentences composed with two discourse type. No sentence with more than 2 discourse types as \n",
      "type_prop >0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#First, our initial number was more or less correct:\n",
    "print(f\"There is {len(df_preproc[df_preproc['type_prop']<1])/len(df_preproc)*100:.2f}% of sentences composed with two discourse type. No sentence with more than 2 discourse types as \\ntype_prop >0.5\") \n",
    "df_preproc[df_preproc['type_prop']<1]['type_prop'].hist(bins=10);\n",
    "\n",
    "## FAUX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "c15232b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:22:16.136987Z",
     "start_time": "2022-02-18T19:22:15.912469Z"
    }
   },
   "outputs": [],
   "source": [
    "# default needed to avoid throwing error\n",
    "df_preproc['label']=df_preproc['type_len'].apply(lambda dict_ : max(dict_,key=dict_.get,default=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "573abbde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:25:13.374575Z",
     "start_time": "2022-02-18T19:25:13.346469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evidence                0.536202\n",
       "Concluding_Statement    0.134127\n",
       "Claim                   0.130290\n",
       "Lead                    0.079529\n",
       "Position                0.043053\n",
       "Counterclaim            0.019343\n",
       "Rebuttal                0.017059\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preproc.label.value_counts()/len(df_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c26fc937",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:25:18.832482Z",
     "start_time": "2022-02-18T19:25:18.775331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claim                   0.347959\n",
       "Evidence                0.316731\n",
       "Position                0.106859\n",
       "Concluding_Statement    0.093594\n",
       "Lead                    0.064487\n",
       "Counterclaim            0.040314\n",
       "Rebuttal                0.030057\n",
       "Name: discourse_type, dtype: float64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.discourse_type.value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fd4880",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T08:22:18.441962Z",
     "start_time": "2022-02-18T08:22:18.438936Z"
    }
   },
   "outputs": [],
   "source": [
    "### ISSUE ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987ce471",
   "metadata": {},
   "source": [
    "### Let's try to tackle our big imbalance issue ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b310556",
   "metadata": {},
   "source": [
    "<strong><font size=3 color='red'>TODO wtf 5% de None ??????</font></strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "6eebaf43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:54:32.717602Z",
     "start_time": "2022-02-18T19:54:32.658082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9596036925746585"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## toudoulou\n",
    "df_shuffled['label'].value_counts().sum()/len(df_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc0ed4b",
   "metadata": {},
   "source": [
    "#### Basic approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "fd2e5632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:51:26.846943Z",
     "start_time": "2022-02-18T19:51:26.111405Z"
    }
   },
   "outputs": [],
   "source": [
    "## Let's create a perfectly balanced dataset with n samples of the less represented discourse\n",
    "n = min(df_shuffled['label'].value_counts())\n",
    "\n",
    "df_balanced = pd.DataFrame(columns = df_shuffled.columns)\n",
    "\n",
    "labels = ['Evidence', 'Lead', 'Claim', 'Concluding_Statement','Rebuttal', 'Counterclaim', 'Position']\n",
    "\n",
    "\n",
    "for label in labels:\n",
    "    df_ = df_shuffled[df_shuffled['label']==label].sample(n)\n",
    "    df_balanced = df_balanced.append(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f48abe97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:51:51.281672Z",
     "start_time": "2022-02-18T19:51:51.276369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11941536361142478"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WOUP # WOUP its never gonna woooorrrrkkkkk\n",
    "len(df_balanced)/len(df_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b046b8d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T21:10:31.172134Z",
     "start_time": "2022-02-20T21:10:31.069462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>ps</th>\n",
       "      <th>type</th>\n",
       "      <th>type_len</th>\n",
       "      <th>type_prop</th>\n",
       "      <th>label</th>\n",
       "      <th>len_sen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>134624</th>\n",
       "      <td>3FB5387479C5</td>\n",
       "      <td>For example, some parents have to work double ...</td>\n",
       "      <td>144 145 146 147 148 149 150 151 152 153 154 15...</td>\n",
       "      <td>Evidence Evidence Evidence Evidence Evidence E...</td>\n",
       "      <td>{'Evidence': 26, 'Claim': 11}</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277578</th>\n",
       "      <td>8197AEA0CC61</td>\n",
       "      <td>On we go with this debate but now on the cons ...</td>\n",
       "      <td>172 173 174 175 176 177 178 179 180 181 182 18...</td>\n",
       "      <td>Evidence Evidence Evidence Evidence Evidence E...</td>\n",
       "      <td>{'Evidence': 15}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38151</th>\n",
       "      <td>0B994B3916FB</td>\n",
       "      <td>Distance learning is an education gained throu...</td>\n",
       "      <td>628 629 630 631 632 633 634 635 636 637 638 63...</td>\n",
       "      <td>Evidence Evidence Evidence Evidence Evidence E...</td>\n",
       "      <td>{'Evidence': 17}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174392</th>\n",
       "      <td>F7149C7BC3B3</td>\n",
       "      <td>Another reason is because of the angle that we...</td>\n",
       "      <td>111 112 113 114 115 116 117 118 119 120 121 12...</td>\n",
       "      <td>Evidence Evidence Evidence Evidence Evidence E...</td>\n",
       "      <td>{'Evidence': 13}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59506</th>\n",
       "      <td>415367DCB6DE</td>\n",
       "      <td>Being a Seagoing Coyboy let's you have the tim...</td>\n",
       "      <td>63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78</td>\n",
       "      <td>Claim Claim Claim Claim. Evidence Evidence Evi...</td>\n",
       "      <td>{'Claim': 4, 'Evidence': 12}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                           sentence  \\\n",
       "134624  3FB5387479C5  For example, some parents have to work double ...   \n",
       "277578  8197AEA0CC61  On we go with this debate but now on the cons ...   \n",
       "38151   0B994B3916FB  Distance learning is an education gained throu...   \n",
       "174392  F7149C7BC3B3  Another reason is because of the angle that we...   \n",
       "59506   415367DCB6DE  Being a Seagoing Coyboy let's you have the tim...   \n",
       "\n",
       "                                                       ps  \\\n",
       "134624  144 145 146 147 148 149 150 151 152 153 154 15...   \n",
       "277578  172 173 174 175 176 177 178 179 180 181 182 18...   \n",
       "38151   628 629 630 631 632 633 634 635 636 637 638 63...   \n",
       "174392  111 112 113 114 115 116 117 118 119 120 121 12...   \n",
       "59506     63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78   \n",
       "\n",
       "                                                     type  \\\n",
       "134624  Evidence Evidence Evidence Evidence Evidence E...   \n",
       "277578  Evidence Evidence Evidence Evidence Evidence E...   \n",
       "38151   Evidence Evidence Evidence Evidence Evidence E...   \n",
       "174392  Evidence Evidence Evidence Evidence Evidence E...   \n",
       "59506   Claim Claim Claim Claim. Evidence Evidence Evi...   \n",
       "\n",
       "                             type_len  type_prop     label len_sen  \n",
       "134624  {'Evidence': 26, 'Claim': 11}   0.702703  Evidence     183  \n",
       "277578               {'Evidence': 15}   1.000000  Evidence      70  \n",
       "38151                {'Evidence': 17}   1.000000  Evidence     108  \n",
       "174392               {'Evidence': 13}   1.000000  Evidence      65  \n",
       "59506    {'Claim': 4, 'Evidence': 12}   0.750000  Evidence      86  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## NB \n",
    "df_balanced.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2665420c",
   "metadata": {},
   "source": [
    "#### Doigt mouillé approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b0ee664e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T20:19:30.098405Z",
     "start_time": "2022-02-18T20:19:29.872698Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evidence                31.431563\n",
       "Concluding_Statement     7.862378\n",
       "Claim                    7.637435\n",
       "Lead                     4.661930\n",
       "Position                 2.523747\n",
       "Counterclaim             1.133882\n",
       "Rebuttal                 1.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Evidence                6.286313\n",
       "Concluding_Statement    3.931189\n",
       "Claim                   3.818717\n",
       "Lead                    2.330965\n",
       "Position                2.523747\n",
       "Counterclaim            1.133882\n",
       "Rebuttal                1.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## another approach : still imbalance but less balanced -__-\n",
    "\n",
    "n = min(df_shuffled['label'].value_counts())\n",
    "display(df_shuffled['label'].value_counts()/n)\n",
    "\n",
    "# idea would be to diminish the ratio ; doigt mouillé bonjour ; we'll obviously keep 'Rebuttal to 1'\n",
    "random_guess_ratio = df_shuffled['label'].value_counts()/n/[5,2,2,2,1,1,1]\n",
    "random_guess_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "000d095b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T20:19:36.979066Z",
     "start_time": "2022-02-18T20:19:36.081558Z"
    }
   },
   "outputs": [],
   "source": [
    "df_balanced_yolo = pd.DataFrame(columns = df_shuffled.columns)\n",
    "\n",
    "labels = ['Evidence', 'Concluding_Statement', 'Claim','Lead', 'Position', 'Counterclaim', 'Rebuttal']\n",
    "\n",
    "for label,weight in zip(labels,random_guess_ratio):\n",
    "    df_ = df_shuffled[df_shuffled['label']==label].sample(int(n*weight))\n",
    "    df_balanced_yolo = df_balanced_yolo.append(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "65fe9099",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T20:19:56.256915Z",
     "start_time": "2022-02-18T20:19:56.201841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evidence                0.298998\n",
       "Concluding_Statement    0.186981\n",
       "Claim                   0.181627\n",
       "Position                0.120030\n",
       "Lead                    0.110869\n",
       "Counterclaim            0.053931\n",
       "Rebuttal                0.047564\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_yolo['label'].value_counts()/df_balanced_yolo['label'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "8c04e042",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T21:12:50.797381Z",
     "start_time": "2022-02-20T21:12:50.788714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                60C7488B4167\n",
       "sentence     Most of the stuuf you do on the job is that yo...\n",
       "ps           113 114 115 116 117 118 119 120 121 122 123 12...\n",
       "type         Evidence Evidence Evidence Evidence Evidence E...\n",
       "type_len     {'Evidence': 13, 'Claim': 5, 'Concluding_State...\n",
       "type_prop                                                  NaN\n",
       "label                                                 Evidence\n",
       "len_sen                                                    105\n",
       "Name: 145468, dtype: object"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced_yolo.loc[145468]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7429b291",
   "metadata": {},
   "source": [
    "#### FYI useless approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e77d7f01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T20:13:21.300700Z",
     "start_time": "2022-02-18T20:13:20.908601Z"
    }
   },
   "outputs": [],
   "source": [
    "### OR NEW APPROACH ! \n",
    "## We will replicate the distribution that we have in the original train.csv file, using number of words\n",
    "\n",
    "df['discourse_len'] = df['predictionstring'].apply(lambda txt : len(txt.split()))\n",
    "types_prop_df=df.groupby('discourse_type')[['discourse_len']].sum().reset_index()\n",
    "types_prop_df['distribution']=types_prop_df['discourse_len']/types_prop_df['discourse_len'].sum()\n",
    "\n",
    "## OK spoiler alert it does not change a thing :) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc341aaa",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0386198e",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b93a4a7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:25:37.998791Z",
     "start_time": "2022-02-18T19:25:37.560451Z"
    }
   },
   "outputs": [],
   "source": [
    "## We can not do a sample train test split : we would loose the connexion to our id ! Let's shuffle our df and create index\n",
    "\n",
    "VAL_SPLIT = .8\n",
    "TEST_SPLIT = .9\n",
    "\n",
    "df_shuffled = df_preproc.sample(frac=1).reset_index(drop=True) #shuffle without replacement keeping all rows\n",
    "\n",
    "LEN=len(df_shuffled)\n",
    "\n",
    "idx_val=int(LEN*VAL_SPLIT)\n",
    "idx_test=int(LEN*TEST_SPLIT)\n",
    "\n",
    "idx_train=list(range(0,idx_val))\n",
    "idx_val=list(range(idx_val,idx_test))\n",
    "idx_test=list(range(idx_test,LEN))\n",
    "\n",
    "assert(len(idx_test)+len(idx_train)+len(idx_val)==LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e9473d5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:25:39.168565Z",
     "start_time": "2022-02-18T19:25:39.064140Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create our train, val, test split\n",
    "\n",
    "x_train = df_shuffled.loc[idx_train,'sentence'].values ## needs the .values to have an array, needed for the model\n",
    "x_val = df_shuffled.loc[idx_val,'sentence'].values ## needs the .values to have an array, needed for the model\n",
    "x_test = df_shuffled.loc[idx_test,'sentence'].values ## needs the .values to have an array, needed for the model\n",
    "\n",
    "y_train = df_shuffled.loc[idx_train,'label'].values ## needs the .values to have an array, needed for the model\n",
    "y_val = df_shuffled.loc[idx_val,'label'].values ## needs the .values to have an array, needed for the model\n",
    "y_test = df_shuffled.loc[idx_test,'label'].values ## needs the .values to have an array, needed for the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e13511fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:25:41.417193Z",
     "start_time": "2022-02-18T19:25:41.224017Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create OHE for y\n",
    "\n",
    "#label mapping\n",
    "list_labels = pd.Series(y_train.flatten()).unique() #Serie + simple\n",
    "label_map = {l:i for i,l in enumerate(list_labels)}\n",
    "label_map\n",
    "\n",
    "y_train_mapped = np.vectorize(label_map.get)(y_train)\n",
    "y_val_mapped = np.vectorize(label_map.get)(y_val)\n",
    "y_test_mapped = np.vectorize(label_map.get)(y_test)\n",
    "\n",
    "\n",
    "y_train_ohe = np.zeros((len(y_train),len(label_map)))\n",
    "y_val_ohe = np.zeros((len(y_val),len(label_map)))\n",
    "y_test_ohe = np.zeros((len(y_train),len(label_map)))\n",
    "\n",
    "y_train_ohe[np.arange(len(y_train)),y_train_mapped]=1\n",
    "y_val_ohe[np.arange(len(y_val)),y_val_mapped]=1\n",
    "y_test_ohe[np.arange(len(y_test)),y_test_mapped]=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b484dc",
   "metadata": {},
   "source": [
    "## Let's take the opportunity to get an idea of a simple baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9c6df044",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:36:22.355422Z",
     "start_time": "2022-02-18T19:36:12.257657Z"
    }
   },
   "outputs": [],
   "source": [
    "#tokenize\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "x_train_tok = tokenizer.texts_to_sequences(x_train)\n",
    "x_val_tok = tokenizer.texts_to_sequences(x_val)\n",
    "x_test_tok = tokenizer.texts_to_sequences(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4fe76052",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:31:58.356419Z",
     "start_time": "2022-02-18T19:31:57.952525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17e5dd8e0>]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAATBklEQVR4nO3dbayc5X3n8e9v7UISuuGYxOuyNlo7i+XKDQqhEXGUVXUUumAgilOJVo5QMSmtpYZ0ky5S1jRSUR8ikd2qKUhpUivQkoiNQ2larEDqUsJ50Rc4QOLwGJYT4wRbEBLAZJ20TZz++2Iuw3A4DzP4nHmA70canfu+ruue+c+lM/M798PMSVUhSXp1+w/DLkCSNHyGgSTJMJAkGQaSJAwDSRKwfNgFvFwTExN1+umnD7uMnv3whz/kpJNOGnYZfRm3msetXrDmQRi3emHpar733nu/X1UrZ+sb2zBYtWoV99xzz7DL6NnU1BSTk5PDLqMv41bzuNUL1jwI41YvLF3NSb49V5+HiSRJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CSxBh/Avl4rd1x67z9B66+cECVSNLwuWcgSTIMJEmGgSQJw0CShGEgScIwkCRhGIyuD3+4c5OkAXjVfs5g5O3bN+wKJL2KuGcgSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEj2GQZLfTfJgkgeSfD7Ja5KsS7I3yXSSLyQ5oY09sa1Pt/61XfdzZWt/JMl5Xe2bW9t0kh2L/iwlSfNaMAySrAb+B/C2qnozsAzYCnwc+ERVnQ48C1zWNrkMeLa1f6KNI8nGtt0vAJuBP0+yLMky4JPA+cBG4H1trCRpQHo9TLQceG2S5cDrgCeAdwE3t/4bgPe25S1tndZ/TpK09l1V9a9V9RgwDZzdbtNVtb+qfgzsamMlSQOyfKEBVXUoyZ8A3wH+GfgH4F7gcFUdbcMOAqvb8mrg8bbt0STPAW9o7Xd13XX3No/PaH/7bLUk2Q5sB1i5ciVTU1MLlT+nK844Om//8dz3bI4cOdLXfZ55+DAA+xa5jn70W/OwjVu9YM2DMG71wnBqXjAMkqyg85f6OuAw8Nd0DvMMXFXtBHYCbNiwoSYnJ1/2fV2649Z5+w9c/PLvezZTU1P0Ve/EBEB/2yyyvmsesnGrF6x5EMatXhhOzb0cJvpl4LGq+l5V/QT4IvBOYKIdNgJYAxxqy4eA0wBa/8nA093tM7aZq12SNCC9hMF3gE1JXteO/Z8DPATcCVzUxmwDbmnLu9s6rf8rVVWtfWu72mgdsB74KnA3sL5dnXQCnZPMu4//qUmSetXLOYO9SW4GvgYcBb5O51DNrcCuJH/c2q5rm1wHfC7JNPAMnTd3qurBJDfRCZKjwOVV9VOAJB8E9tC5Uun6qnpw8Z6iJGkhC4YBQFVdBVw1o3k/nSuBZo79F+BX57ifjwEfm6X9NuC2XmqRJC0+P4EsSTIMJEmGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAk0eNXWI+jtQv8W0tJ0gvcM5AkGQaSJMNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJJ4BX+F9fHq5SuwD1x94QAqkaSl556BJMkwkCQZBpIkDANJEoaBJIkewyDJRJKbk3wzycNJ3pHklCS3J3m0/VzRxibJtUmmk9yX5Kyu+9nWxj+aZFtX+y8mub9tc22SLP5TlSTNpdc9g2uAv6+qnwfeAjwM7ADuqKr1wB1tHeB8YH27bQc+BZDkFOAq4O3A2cBVxwKkjfmtru02H9/TkiT1Y8EwSHIy8EvAdQBV9eOqOgxsAW5ow24A3tuWtwCfrY67gIkkpwLnAbdX1TNV9SxwO7C59b2+qu6qqgI+23VfkqQB6OVDZ+uA7wF/meQtwL3Ah4BVVfVEG/MksKotrwYe79r+YGubr/3gLO0vkWQ7nb0NVq5cydTU1JxFX3HG0YWf2XGa7/FnOnLkSF/jzzx8GIB9fWyz2PqtedjGrV6w5kEYt3phODX3EgbLgbOA36mqvUmu4YVDQgBUVSWppShwxuPsBHYCbNiwoSYnJ+cce2kPnyA+XgcunvvxZ5qammK+el9iYgKgv20WWd81D9m41QvWPAjjVi8Mp+ZezhkcBA5W1d62fjOdcPhuO8RD+/lU6z8EnNa1/ZrWNl/7mlnaJUkDsmAYVNWTwONJNrSmc4CHgN3AsSuCtgG3tOXdwCXtqqJNwHPtcNIe4NwkK9qJ43OBPa3vB0k2tauILum6L0nSAPT6RXW/A9yY5ARgP/B+OkFyU5LLgG8Dv9bG3gZcAEwDP2pjqapnkvwRcHcb94dV9Uxb/gDwV8BrgS+3myRpQHoKg6raB7xtlq5zZhlbwOVz3M/1wPWztN8DvLmXWiRJi89PIEuSDANJkmEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEmijzBIsizJ15N8qa2vS7I3yXSSLyQ5obWf2NanW//arvu4srU/kuS8rvbNrW06yY5FfH6SpB70s2fwIeDhrvWPA5+oqtOBZ4HLWvtlwLOt/RNtHEk2AluBXwA2A3/eAmYZ8EngfGAj8L42VpI0ID2FQZI1wIXAZ9p6gHcBN7chNwDvbctb2jqt/5w2fguwq6r+taoeA6aBs9ttuqr2V9WPgV1trCRpQHrdM/gz4CPAv7X1NwCHq+poWz8IrG7Lq4HHAVr/c2388+0ztpmrXZI0IMsXGpDk3cBTVXVvksklr2j+WrYD2wFWrlzJ1NTUnGOvOOPonH2LZb7Hn+nIkSN9jT/z8GEA9vWxzWLrt+ZhG7d6wZoHYdzqheHUvGAYAO8E3pPkAuA1wOuBa4CJJMvbX/9rgENt/CHgNOBgkuXAycDTXe3HdG8zV/uLVNVOYCfAhg0banJycs6iL91xaw9P7fgcuHjux59pamqK+ep9iYkJgP62WWR91zxk41YvWPMgjFu9MJyaFzxMVFVXVtWaqlpL5wTwV6rqYuBO4KI2bBtwS1ve3dZp/V+pqmrtW9vVRuuA9cBXgbuB9e3qpBPaY+xelGcnSepJL3sGc/lfwK4kfwx8HbiutV8HfC7JNPAMnTd3qurBJDcBDwFHgcur6qcAST4I7AGWAddX1YPHUZckqU99hUFVTQFTbXk/nSuBZo75F+BX59j+Y8DHZmm/Dbitn1okSYvHTyBLkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkju9DZ696axf4yosDV184oEok6fi4ZyBJMgwkSYaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJJED2GQ5LQkdyZ5KMmDST7U2k9JcnuSR9vPFa09Sa5NMp3kviRndd3Xtjb+0STbutp/Mcn9bZtrk2QpnqwkaXa97BkcBa6oqo3AJuDyJBuBHcAdVbUeuKOtA5wPrG+37cCnoBMewFXA24GzgauOBUgb81td220+/qcmSerVgmFQVU9U1dfa8v8HHgZWA1uAG9qwG4D3tuUtwGer4y5gIsmpwHnA7VX1TFU9C9wObG59r6+qu6qqgM923ZckaQCW9zM4yVrgrcBeYFVVPdG6ngRWteXVwONdmx1sbfO1H5ylfbbH305nb4OVK1cyNTU1Z61XnHG0h2e0tLrrO3LkyLz1znTm4cMA7Otjm8XWb83DNm71gjUPwrjVC8OpuecwSPKzwN8AH66qH3Qf1q+qSlJLUN+LVNVOYCfAhg0banJycs6xl+64danLWdCBiyefX56ammK+el9iYgKgv20WWd81D9m41QvWPAjjVi8Mp+aeriZK8jN0guDGqvpia/5uO8RD+/lUaz8EnNa1+ZrWNl/7mlnaJUkD0svVRAGuAx6uqj/t6toNHLsiaBtwS1f7Je2qok3Ac+1w0h7g3CQr2onjc4E9re8HSTa1x7qk674kSQPQy2GidwK/DtyfZF9r+z3gauCmJJcB3wZ+rfXdBlwATAM/At4PUFXPJPkj4O427g+r6pm2/AHgr4DXAl9uN0nSgCwYBlX1T8Bc1/2fM8v4Ai6f476uB66fpf0e4M0L1SJJWhp+AlmS1N+lperP2q4rmq444+hLrnA6cPWFgy5JkmblnoEkyTCQJBkGkiQMA0kSY3wC+Z9/8tMXnaCVJL187hlIkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJDHGX1T3SjDfF+3t2v80m970hgFWI+nVzD0DSZJhIEkyDCRJGAaSJAwDSRKGgSQJw0CShGEgScIPnY20u/Y/zdZ5PpgGcODqCwdUjaRXMvcMJEmGgSTJMJAk4TmDsTffl92B5xQk9cY9A0mSYSBJGqHDREk2A9cAy4DPVNXVQy7pFcHDSJJ6MRJhkGQZ8EngvwMHgbuT7K6qh4Zb2SvffGFxxRlHmRxcKZKGaCTCADgbmK6q/QBJdgFbAMNgyBbasxgE916kpZeqGnYNJLkI2FxVv9nWfx14e1V9cMa47cD2tvpm4IGBFnp83gh8f9hF9Gncah63esGaB2Hc6oWlq/m/VNXK2TpGZc+gJ1W1E9gJkOSeqnrbkEvq2bjVC+NX87jVC9Y8CONWLwyn5lG5mugQcFrX+prWJkkagFEJg7uB9UnWJTkB2ArsHnJNkvSqMRKHiarqaJIPAnvoXFp6fVU9uMBmO5e+skU1bvXC+NU8bvWCNQ/CuNULQ6h5JE4gS5KGa1QOE0mShsgwkCSNXxgk2ZzkkSTTSXYMu55jkpyW5M4kDyV5MMmHWvspSW5P8mj7uaK1J8m17Xncl+SsIdW9LMnXk3ypra9LsrfV9YV2Qp8kJ7b16da/dkj1TiS5Ock3kzyc5B2jPMdJfrf9PjyQ5PNJXjNqc5zk+iRPJXmgq63vOU2yrY1/NMm2IdT8f9rvxX1J/jbJRFffla3mR5Kc19U+sPeT2Wru6rsiSSV5Y1sf/DxX1djc6Jxc/hbwJuAE4BvAxmHX1Wo7FTirLf9H4P8BG4H/Dexo7TuAj7flC4AvAwE2AXuHVPf/BP4v8KW2fhOwtS1/GvjttvwB4NNteSvwhSHVewPwm235BGBiVOcYWA08Bry2a24vHbU5Bn4JOAt4oKutrzkFTgH2t58r2vKKAdd8LrC8LX+8q+aN7b3iRGBdew9ZNuj3k9lqbu2n0bl45tvAG4c1zwN7YSzSZL4D2NO1fiVw5bDrmqPWW+h819IjwKmt7VTgkbb8F8D7usY/P26ANa4B7gDeBXyp/eJ9v+sF9fx8t1/Wd7Tl5W1cBlzvye3NNTPaR3KO6YTB4+2Fu7zN8XmjOMfA2hlvrH3NKfA+4C+62l80bhA1z+j7FeDGtvyi94lj8zyM95PZagZuBt4CHOCFMBj4PI/bYaJjL65jDra2kdJ2798K7AVWVdUTretJYFVbHoXn8mfAR4B/a+tvAA5X1dFZanq+3tb/XBs/SOuA7wF/2Q5tfSbJSYzoHFfVIeBPgO8AT9CZs3sZ7Tk+pt85HYXf526/QecvaxjhmpNsAQ5V1TdmdA285nELg5GX5GeBvwE+XFU/6O6rTpSPxLW8Sd4NPFVV9w67lj4sp7Ob/amqeivwQzqHMJ43YnO8gs4XLq4D/jNwErB5qEW9DKM0p71I8lHgKHDjsGuZT5LXAb8H/P6wa4HxC4OR/tqKJD9DJwhurKovtubvJjm19Z8KPNXah/1c3gm8J8kBYBedQ0XXABNJjn0Ysbum5+tt/ScDTw+wXuj8FXSwqva29ZvphMOozvEvA49V1feq6ifAF+nM+yjP8TH9zumw5xqAJJcC7wYubiEGo1vzf6Xzh8I32utwDfC1JD83T21LVvO4hcHIfm1FkgDXAQ9X1Z92de0Gjp3x30bnXMKx9kvaVQObgOe6dsuXXFVdWVVrqmotnXn8SlVdDNwJXDRHvceex0Vt/ED/WqyqJ4HHk2xoTefQ+ZrzkZxjOoeHNiV5Xfv9OFbvyM5xl37ndA9wbpIVbY/o3NY2MOn8g6yPAO+pqh91de0GtrartdYB64GvMuT3k6q6v6r+U1Wtba/Dg3QuQnmSYczzUp4sWaITMBfQuVLnW8BHh11PV13/jc6u9H3Avna7gM4x3zuAR4F/BE5p40PnH/p8C7gfeNsQa5/khauJ3kTnhTIN/DVwYmt/TVufbv1vGlKtZwL3tHn+OzpXVIzsHAN/AHyTztetf47OFS0jNcfA5+mc0/gJnTeky17OnNI5Tj/dbu8fQs3TdI6nH3v9fbpr/EdbzY8A53e1D+z9ZLaaZ/Qf4IUTyAOfZ7+OQpI0doeJJElLwDCQJBkGkiTDQJKEYSBJwjCQJGEYSJKAfwciklYD4EDKbwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check distribution of length of distribution to determine padding \n",
    "\n",
    "df_shuffled['len_sen']=df_shuffled['sentence'].apply(len)\n",
    "df_shuffled['len_sen'].hist(bins=100)\n",
    "plt.xlim(0,1500)\n",
    "plt.plot([256,256],[0,90000],c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f14a6321",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:31:09.867587Z",
     "start_time": "2022-02-18T19:31:09.850930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.97% sentences captured'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-len(df_shuffled[df_shuffled.len_sen>256])/len(df_shuffled)).__format__('.2f')+'% sentences captured'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "169157e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:33:01.552323Z",
     "start_time": "2022-02-18T19:33:00.366541Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#padding\n",
    "\n",
    "x_train_pad = tf.keras.preprocessing.sequence.pad_sequences(x_train_tok, \n",
    "                                                            dtype='float32', padding='post',maxlen=256)\n",
    "x_val_pad = tf.keras.preprocessing.sequence.pad_sequences(x_val_tok, \n",
    "                                                          dtype='float32', padding='post',maxlen=256)\n",
    "x_test_pad = tf.keras.preprocessing.sequence.pad_sequences(x_test_tok, \n",
    "                                                           dtype='float32', padding='post',maxlen=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02daab4",
   "metadata": {},
   "source": [
    "## Using simple embeddings and LSTM layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "251e781c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:33:08.217687Z",
     "start_time": "2022-02-18T19:33:08.211819Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47842"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Define variables for our embedding layer\n",
    "vocab_size = len(tokenizer.word_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadfc7f",
   "metadata": {},
   "source": [
    "### Model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "dafa9422",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:38:26.440865Z",
     "start_time": "2022-02-18T19:38:26.435655Z"
    }
   },
   "outputs": [],
   "source": [
    "## Create simplest model e v e r \n",
    "\n",
    "def simple_model():\n",
    "    \n",
    "    x = tf.keras.layers.Embedding(input_dim=vocab_size + 1, output_dim=64, mask_zero=True)(inputs)\n",
    "    \n",
    "    x = tf.keras.layers.LSTM(units = 256, activation = 'tanh', return_sequence=True)(x)\n",
    "    x = tf.keras.layers.LSTM(units = 128, activation = 'tanh')(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(58,activation='relu')(x)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(8,activation='softmax')(x)\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "84a27b3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T19:53:06.521249Z",
     "start_time": "2022-02-18T19:53:06.516029Z"
    }
   },
   "outputs": [],
   "source": [
    "def simple_model_bidirectionnal():\n",
    "    \n",
    "    x = tf.keras.layers.Embedding(input_dim=vocab_size + 1, output_dim=64, mask_zero=True)(inputs)\n",
    "    \n",
    "    x = tf.keras.layers.Bidirectional(LSTM(units = 256, activation = 'tanh', return_sequence=True))(x)\n",
    "    x = tf.keras.layers.Bidirectional(LSTM(units = 128, activation = 'tanh'))(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(58,activation='relu')(x)\n",
    "    \n",
    "    outputs = tf.keras.layers.Dense(8,activation='softmax')(x)\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c9752a",
   "metadata": {},
   "source": [
    "### Model compilation and callbacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "515bdc42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T20:31:25.862634Z",
     "start_time": "2022-02-18T20:31:25.705832Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-18 21:31:25.802181: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#init objects\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "metrics = tf.keras.metrics.CategoricalAccuracy()\n",
    "lr_scheduler \n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "d4e93e5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T20:38:59.498366Z",
     "start_time": "2022-02-18T20:38:59.492076Z"
    }
   },
   "outputs": [],
   "source": [
    "# callbacks \n",
    "\n",
    "#paths\n",
    "checkpoints_path_simple = '/content/drive/MyDrive/feedback-prize/checkpoints/sentences_simple.ckpt'\n",
    "checkpoints_path_bi = '/content/drive/MyDrive/feedback-prize/checkpoints/sentences_bi.ckpt'\n",
    "logdir = '/content/drive/MyDrive/feedback-drive/logs/'\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=1)\n",
    "\n",
    "checkpoint_saver_simple = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoints_path_simple,\n",
    "                                                      save_weights_only=True,\n",
    "                                                      save_best_only = True,\n",
    "                                                      monitor = 'val_categorical_accuracy',\n",
    "                                                      mode = 'max',\n",
    "                                                      verbose = 1)\n",
    "\n",
    "checkpoint_saver_simple = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoints_path_bi,\n",
    "                                                      save_weights_only=True,\n",
    "                                                      save_best_only = True,\n",
    "                                                      monitor = 'val_categorical_accuracy',\n",
    "                                                      mode = 'max',\n",
    "                                                      verbose = 1)\n",
    "\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b146d57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb8b3e17",
   "metadata": {},
   "source": [
    "## Transformers as embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ace6a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-18T08:15:12.742362Z",
     "start_time": "2022-02-18T08:15:03.722316Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TFBertModel,AutoTokenizer\n",
    "pretrained_bert = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a105e43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tok=tokenizer(list(x_train),truncation=True,max_length=DISCOURSE_LEN,padding='max_length',\n",
    "              return_token_type_ids=False,return_tensors='np')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
