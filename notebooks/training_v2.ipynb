{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a81d29d",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Imports-&amp;-Variables\" data-toc-modified-id=\"Imports-&amp;-Variables-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Imports &amp; Variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Colab\" data-toc-modified-id=\"Colab-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Colab</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Variables\" data-toc-modified-id=\"Variables-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Variables</a></span></li></ul></li><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load data</a></span></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-architecture\" data-toc-modified-id=\"Model-architecture-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Model architecture</a></span></li><li><span><a href=\"#Loss,-Optimizer,-Metrics\" data-toc-modified-id=\"Loss,-Optimizer,-Metrics-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Loss, Optimizer, Metrics</a></span></li><li><span><a href=\"#Model-training\" data-toc-modified-id=\"Model-training-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Model training</a></span></li><li><span><a href=\"#Model-loading\" data-toc-modified-id=\"Model-loading-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Model loading</a></span></li><li><span><a href=\"#Model-evaluation\" data-toc-modified-id=\"Model-evaluation-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Model evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Get-predictions\" data-toc-modified-id=\"Get-predictions-3.5.1\"><span class=\"toc-item-num\">3.5.1&nbsp;&nbsp;</span>Get predictions</a></span></li><li><span><a href=\"#Evaluate-test-split\" data-toc-modified-id=\"Evaluate-test-split-3.5.2\"><span class=\"toc-item-num\">3.5.2&nbsp;&nbsp;</span>Evaluate test split</a></span><ul class=\"toc-item\"><li><span><a href=\"#F1-Report\" data-toc-modified-id=\"F1-Report-3.5.2.1\"><span class=\"toc-item-num\">3.5.2.1&nbsp;&nbsp;</span>F1 Report</a></span></li><li><span><a href=\"#Confusion-Matrix\" data-toc-modified-id=\"Confusion-Matrix-3.5.2.2\"><span class=\"toc-item-num\">3.5.2.2&nbsp;&nbsp;</span>Confusion Matrix</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e66f60a",
   "metadata": {},
   "source": [
    "Blabla to add ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af21fa2",
   "metadata": {},
   "source": [
    "# Imports & Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaafcdc1",
   "metadata": {},
   "source": [
    "## Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eb34847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T13:41:31.812786Z",
     "start_time": "2022-02-08T13:41:31.802901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the notebook on \u001b[34myour machine\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    COLAB = True\n",
    "    print('Running the notebook on',colored('Colab','yellow'))\n",
    "except:\n",
    "    COLAB = False\n",
    "    print('Running the notebook on',colored('your machine','blue'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6443d60f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c0d1bee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T13:41:40.361394Z",
     "start_time": "2022-02-08T13:41:33.519414Z"
    }
   },
   "outputs": [],
   "source": [
    "## utilities\n",
    "import os \n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "## classics \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "## deep\n",
    "import tensorflow as tf\n",
    "\n",
    "if COLAB:\n",
    "    !pip install --quiet transformers\n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "460a7dec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T13:42:04.718650Z",
     "start_time": "2022-02-08T13:42:04.715456Z"
    }
   },
   "outputs": [],
   "source": [
    "#evaluation metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e4f08",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4acaafab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T14:36:18.861298Z",
     "start_time": "2022-02-08T14:36:18.856038Z"
    }
   },
   "outputs": [],
   "source": [
    "#Max len of essay \n",
    "SEQ_LEN = 1024 ## THIS SHOULD NOT BE CHANGED without appropriate changes in the preprocessing \n",
    "\n",
    "#Train, val, test split proportion\n",
    "VAL_SPLIT = 0.8\n",
    "TEST_SPLIT = 0.9\n",
    "\n",
    "#Batch size\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "#Data version\n",
    "VERSION=3\n",
    "\n",
    "# Load weights of trained model\n",
    "LOAD_MODEL = True\n",
    "MODEL_NAME = 'fulltraining_lstm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7efa402a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T14:33:20.543692Z",
     "start_time": "2022-02-08T14:33:20.532689Z"
    }
   },
   "outputs": [],
   "source": [
    "## Paths\n",
    "\n",
    "## if running in colab, mount drive\n",
    "if COLAB:\n",
    "    drive.mount('/content/drive')\n",
    "    PATH='/content/drive/MyDrive/feedback-prize/'\n",
    "else:\n",
    "    PATH=os.path.dirname(os.path.abspath(''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178d6319",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "The data is already preprocessed in another notebook.\n",
    "\n",
    "The preprocessed data is loaded and splitted in `train`, `val`, `test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "98e9bc4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T16:51:35.915351Z",
     "start_time": "2022-02-08T16:51:32.856432Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load train and test data\n",
    "with open(os.path.join(PATH,'raw_data',f'dataset_v{VERSION}.pickle'),'rb') as file:\n",
    "    dataset = pickle.load(file)\n",
    "    \n",
    "with open(os.path.join(PATH,'raw_data',f'dataset_test_v{VERSION}.pickle'),'rb') as file:\n",
    "    dataset_inf = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c01c00ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T15:59:20.690009Z",
     "start_time": "2022-02-08T15:59:19.205664Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load preprocessed.csv file as it will be needed to retrieve predictions\n",
    "df_essays = pd.read_csv(os.path.join(PATH,'raw_data',f'preprocessed_v{VERSION}.csv'))\n",
    "df_inf = pd.read_csv(os.path.join(PATH,'raw_data',f'preprocessed_inf_v{VERSION}.csv'),index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06633885",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T14:40:33.914563Z",
     "start_time": "2022-02-08T14:40:33.906719Z"
    }
   },
   "outputs": [],
   "source": [
    "## Creating splits indexes\n",
    "\n",
    "LEN=len(dataset['labels'])\n",
    "\n",
    "idx_val=int(LEN*VAL_SPLIT)\n",
    "idx_test=int(LEN*TEST_SPLIT)\n",
    "\n",
    "idx_train=list(range(0,idx_val))\n",
    "idx_val=list(range(idx_val,idx_test))\n",
    "idx_test=list(range(idx_test,LEN))\n",
    "\n",
    "assert(len(idx_test)+len(idx_train)+len(idx_val)==LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d5694515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T15:00:32.841686Z",
     "start_time": "2022-02-08T15:00:27.986785Z"
    }
   },
   "outputs": [],
   "source": [
    "## Splitting dataset\n",
    "\n",
    "#train\n",
    "X_train = {\n",
    "    'input_ids' : dataset['inputs']['input_ids'][idx_train],\n",
    "    'attention_mask' : dataset['inputs']['attention_mask'][idx_train]\n",
    "}\n",
    "\n",
    "y_train = dataset['labels'][idx_train]\n",
    "ps_train = dataset['predictionstrings'][idx_train]\n",
    "\n",
    "#val\n",
    "X_val = {\n",
    "    'input_ids' : dataset['inputs']['input_ids'][idx_val],\n",
    "    'attention_mask' : dataset['inputs']['attention_mask'][idx_val]\n",
    "}\n",
    "\n",
    "y_val = dataset['labels'][idx_val]\n",
    "ps_val = dataset['predictionstrings'][idx_val]\n",
    "\n",
    "\n",
    "#test\n",
    "X_test = {\n",
    "    'input_ids' : dataset['inputs']['input_ids'][idx_test],\n",
    "    'attention_mask' : dataset['inputs']['attention_mask'][idx_test]\n",
    "}\n",
    "\n",
    "y_test = dataset['labels'][idx_test]\n",
    "ps_test = dataset['predictionstrings'][idx_test]\n",
    "\n",
    "#inference\n",
    "X_inf = dataset_test['inputs']\n",
    "ps_inf = dataset_test['predictionstrings']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06895f0e",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce61fc80",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dbf3d6ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T15:05:09.982796Z",
     "start_time": "2022-02-08T15:04:51.874202Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-08 16:04:53.797955: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some layers from the model checkpoint at allenai/longformer-base-4096 were not used when initializing TFLongformerModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFLongformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFLongformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFLongformerModel were initialized from the model checkpoint at allenai/longformer-base-4096.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFLongformerModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "## Instantiate model Longformer to be used as backbone\n",
    "backbone = TFAutoModel.from_pretrained('allenai/longformer-base-4096')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4b31d749",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T15:05:19.028832Z",
     "start_time": "2022-02-08T15:05:19.014958Z"
    }
   },
   "outputs": [],
   "source": [
    "# init model\n",
    "\n",
    "def init_model():\n",
    "    input_ids = tf.keras.layers.Input(shape=(SEQ_LEN,),dtype='int32')\n",
    "    attention_mask = tf.keras.layers.Input(shape=(SEQ_LEN,),dtype='int32')\n",
    "    \n",
    "    x = backbone({'input_ids':input_ids,\n",
    "                 'attention_mask':attention_mask})[0]\n",
    "\n",
    "    backbone.trainable = False\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units = 512,\n",
    "                                                           activation = 'tanh',\n",
    "                                                           dropout=.2,\n",
    "                                                           return_sequences=True))(x)\n",
    "    x_res = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units = 512,\n",
    "                                                           activation = 'tanh',\n",
    "                                                           dropout=.2,\n",
    "                                                           return_sequences=True))(x)\n",
    "    \n",
    "\n",
    "    x = tf.keras.layers.add([x,x_res])\n",
    "    output = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(16,activation = 'softmax'))(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs={'input_ids':input_ids,\n",
    "                                          'attention_mask':attention_mask},outputs=output)\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "805fd880",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T15:08:40.730243Z",
     "start_time": "2022-02-08T15:08:32.179279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "## instantiate the model, plot the graph\n",
    "model = init_model()\n",
    "\n",
    "tf.keras.utils.plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba134f3f",
   "metadata": {},
   "source": [
    "## Loss, Optimizer, Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e741083",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T15:19:20.793041Z",
     "start_time": "2022-02-08T15:19:20.726503Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating homemade metric\n",
    "\n",
    "def accuracy_masked_func(y_true,y_pred):\n",
    "    y_pred = tf.cast(tf.argmax(y_pred,axis=-1),'int32')\n",
    "    y_true = tf.cast(y_true,'int32')\n",
    "    y_true = tf.cast(tf.argmax(y_true,axis=-1),'int32') #for y_pred and y_true to match\n",
    "    mask = tf.cast(y_true != 15,'int32') #create a mask\n",
    "    matches = tf.cast(tf.equal(y_true,y_pred),'int32')*mask #calculate the matches ignoring the masking\n",
    "    accuracy = tf.math.reduce_sum(matches,axis=-1)/tf.maximum(tf.math.reduce_sum(mask,axis=-1),1)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39f32227",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T15:20:32.714566Z",
     "start_time": "2022-02-08T15:20:32.434987Z"
    }
   },
   "outputs": [],
   "source": [
    "# define loss and metrics \n",
    "loss = tf.keras.losses.CategoricalCrossentropy(name='categorical_crossentropy')\n",
    "cat_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "masked_accuracy = tf.keras.metrics.MeanMetricWrapper(fn=accuracy_masked_func)\n",
    "\n",
    "# RMSProp optimizer with clip value and small lr to avoid exploiding gradient \n",
    "opt = tf.keras.optimizers.RMSprop(clipvalue=.5,learning_rate=0.0001)\n",
    "\n",
    "#compile\n",
    "model.compile(optimizer=opt,loss=loss,metrics=[cat_accuracy,masked_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af59f074",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8de8c166",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T15:35:00.705395Z",
     "start_time": "2022-02-08T15:35:00.630108Z"
    }
   },
   "outputs": [],
   "source": [
    "#### CALLBACKS\n",
    "\n",
    "timestamp = datetime.today().__format__('%d%m_%Hh%M')\n",
    "\n",
    "checkpoints_path = f'{PATH}{MODEL_NAME}/{MODEL_NAME}_{timestamp}.ckpt'\n",
    "logdir = '/content/drive/MyDrive/feedback-prize/logs/'\n",
    "\n",
    "\n",
    "#early stopping\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=1,restore_best_weights=True)\n",
    "\n",
    "#save weights at every epoch\n",
    "checkpoint_saver = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoints_path,\n",
    "                                                      save_weights_only=True,\n",
    "                                                      save_best_only = True,\n",
    "                                                      monitor = 'val_categorical_accuracy',\n",
    "                                                      mode = 'max',\n",
    "                                                      verbose = 1)\n",
    "\n",
    "#logs for tensorboard\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# list callbacks\n",
    "\n",
    "callbacks=[es,checkpoint_saver,tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d14a118f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T15:36:39.914302Z",
     "start_time": "2022-02-08T15:36:39.910221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model weights below\n"
     ]
    }
   ],
   "source": [
    "## TRAINING\n",
    "if not LOAD_MODEL:\n",
    "    history = model.fit(X_train,y_train,\n",
    "                        validation_data= (X_val,y_val),\n",
    "                        epochs=30,callbacks=callbacks,batch_size=BATCH_SIZE)\n",
    "else:\n",
    "    print('Loading model weights below')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9b34e7",
   "metadata": {},
   "source": [
    "## Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1ba31d50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-08T15:40:17.197843Z",
     "start_time": "2022-02-08T15:40:17.158574Z"
    }
   },
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /Users/arthurcollard/code/arthurcol/feedback_prize/fulltraining_lstm/fulltraining_lstm_0402.ckpt",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zd/9ts3jb2s5472mty2sgdddp3m0000gn/T/ipykernel_11471/829061432.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'0402'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{MODEL_NAME}_{ckpt}.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/feedback-prize/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/feedback-prize/lib/python3.8/site-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0;34m'Failed to find any '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       'matching files for') in error_message:\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m   elif 'Sliced checkpoints are not supported' in error_message or (\n\u001b[1;32m     37\u001b[0m       \u001b[0;34m'Data type '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /Users/arthurcollard/code/arthurcol/feedback_prize/fulltraining_lstm/fulltraining_lstm_0402.ckpt"
     ]
    }
   ],
   "source": [
    "ckpt = '0402'\n",
    "model.load_weights(os.path.join(PATH,MODEL_NAME,f'{MODEL_NAME}_{ckpt}.ckpt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b0466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model eval on val set \n",
    "model.evaluate(X_val,y_val,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0d1923",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0aa2f6",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4586e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(y_pred,ps):\n",
    "    \"\"\"\n",
    "    Generate readable predictions from the output of the model.\n",
    "\n",
    "    Args:\n",
    "        y_pred (ndarray): output of the model\n",
    "        ps (ndarray): predictionstring referring to the token predicted\n",
    "\n",
    "    Returns:\n",
    "        DataFrame : DataFrame with class and predictionstrings\n",
    "    \"\"\"\n",
    "    \n",
    "    seq = np.argmax(y_pred,axis=-1) #out of OHE\n",
    "\n",
    "    labels = []\n",
    "    predictionstrings = []\n",
    "    counts = []\n",
    "    \n",
    "    counter=dict()\n",
    "    \n",
    "    for tok,pos in zip(seq,ps):\n",
    "        \n",
    "        if tok <= 13:\n",
    "            lab = reversed_mapping[tok]\n",
    "            labels.append(lab)\n",
    "            predictionstrings.append(pos)\n",
    "            if len(labels)<2:\n",
    "                counts.append(str(1))\n",
    "                counter.setdefault(lab,1)\n",
    "                continue\n",
    "            if lab == labels[-2]:\n",
    "                counts.append(str(counter[lab]))\n",
    "            else: \n",
    "                try:\n",
    "                    counter[lab]+=1\n",
    "                except KeyError:\n",
    "                    counter.setdefault(lab,1)\n",
    "                counts.append(str(counter[lab]))\n",
    "    \n",
    "    preds = pd.DataFrame([labels,counts,predictionstrings],index=['class','count','predictionstring']).T\n",
    "    preds['class'] += ' ' + preds['count'].astype(str)\n",
    "    preds = preds.groupby('class',sort=False).agg({'predictionstring':list}).reset_index()\n",
    "    preds['class']=preds['class'].apply(lambda txt : txt.split()[0])\n",
    "    preds['predictionstring']=preds['predictionstring'].apply(lambda l_ : [str(l) for l in l_])\n",
    "    preds['predictionstring']=preds['predictionstring'].apply(lambda l_ : ' '.join(l_))\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfbd22c",
   "metadata": {},
   "source": [
    "### Evaluate test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d63b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on test split\n",
    "y_pred = model(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234d1115",
   "metadata": {},
   "source": [
    "#### F1 Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87454dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create two DF with preds and ground truth\n",
    "\n",
    "y_true = np.argmax(y_test,axis=-1)\n",
    "y_pred = np.argmax(y_pred,axis=-1)\n",
    "\n",
    "ps = ps_test\n",
    "\n",
    "true_df = pd.DataFrame()\n",
    "pred_df = pd.DataFrame()\n",
    "\n",
    "for i,idx in tqdm(enumerate(idx_test),desc='Reading predictions',total=len(idx_test)): ## CHANGE idx_test\n",
    "    \n",
    "    true_ = get_preds(y_true[i],ps[i])\n",
    "    pred_ = get_preds(y_pred[i],ps[i])\n",
    "    \n",
    "    true_['id']=df_essays.iloc[idx]['id']\n",
    "    pred_['id']=df_essays.iloc[idx]['id']\n",
    "    \n",
    "    true_df = true_df.append(true_)\n",
    "    pred_df = pred_df.append(pred_)\n",
    "    \n",
    "true_df['unique_id'] = pd.util.hash_pandas_object(true_df,hash_key='1234567890123456')\n",
    "pred_df['unique_id'] = pd.util.hash_pandas_object(pred_df,hash_key='azerty1234567890')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d45514",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determine whether a prediction is a true positive or not\n",
    "\n",
    "def true_positive(predictionstring_true,predictionstring_pred):\n",
    "    ps_true = set(predictionstring_true.split(' '))\n",
    "    ps_pred = set(predictionstring_pred.split(' '))\n",
    "    \n",
    "    inter = ps_pred.intersection(ps_true)\n",
    "    overlap_1 = len(inter)/len(ps_true)\n",
    "    overlap_2 = len(inter)/len(ps_pred)\n",
    "    \n",
    "    if overlap_1 >= .5 and overlap_2 >= .5:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "## vectorize the funct\n",
    "true_positive_vect = np.vectorize(true_positive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e811bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge the 2 DF to compute F1 \n",
    "\n",
    "merged_df = pred_df.merge(true_df,how = 'outer',on=['id','class'],suffixes=('_pred','_true'))\n",
    "\n",
    "## if a pred is not matched it is a FN ; if the truth is not matched it is a FP\n",
    "\n",
    "#creating separate columns \n",
    "merged_df['FP'] = np.where(merged_df.predictionstring_true.isna(), 1, 0)\n",
    "merged_df['FN'] = np.where(merged_df.predictionstring_pred.isna(), 1, 0)\n",
    "\n",
    "\n",
    "#cleaning nan for the true positive function\n",
    "merged_df['predictionstring_pred'].fillna('',inplace=True)\n",
    "merged_df['predictionstring_true'].fillna('',inplace=True)\n",
    "\n",
    "\n",
    "merged_df['TP'] = true_positive_vect(merged_df['predictionstring_true'],merged_df['predictionstring_pred'])\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b518be6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating f1 function\n",
    "def f1_score(fp,fn,tp):\n",
    "    return tp/(tp+.5*(fp+fn))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## group by class for F1 score calculation\n",
    "f1_df = merged_df.groupby('class').sum()\n",
    "\n",
    "#apply to the df\n",
    "f1_df['f1']=f1_score(f1_df.FP,f1_df.FN,f1_df.TP)\n",
    "\n",
    "#Create a total row\n",
    "f1_df.loc['Total']=f1_df.mean()\n",
    "\n",
    "## weighted average\n",
    "\n",
    "f1_df['support'] = true_df.groupby('class').count()['id']\n",
    "\n",
    "f1_df['f1_weighted']=f1_df['f1']*(f1_df['support']/f1_df['support'].sum())\n",
    "f1_df.loc['Total','support']=f1_df.support.sum()\n",
    "f1_df.loc['Total','f1_weighted']=f1_df.f1_weighted.sum()\n",
    "\n",
    "# impute correct values for the Total row for TP FN FP \n",
    "\n",
    "f1_df.loc['Total','FP'] = f1_df.loc[:'Rebuttal','FP'].sum()\n",
    "f1_df.loc['Total','FN'] = f1_df.loc[:'Rebuttal','FN'].sum()\n",
    "f1_df.loc['Total','TP'] = f1_df.loc[:'Rebuttal','TP'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d296aa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PRINT REPORT\n",
    "\n",
    "print(f\"F1 Macro Score = {f1_df.loc['Total','f1']:.2f}%\")\n",
    "\n",
    "\n",
    "print(f\"F1 Micro Score = {f1_score(f1_df.loc['Total','FP'],f1_df.loc['Total','FN'],f1_df.loc['Total','TP']):.2f}%\")\n",
    "\n",
    "print(f\"F1 Weighted Score = {f1_df.loc['Total','f1_weighted']:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cd3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(y=f1_df.reset_index().loc[:6,'f1'],x=f1_df.index[:-1],palette='Set2')\n",
    "plt.xticks(rotation=90)\n",
    "locs,_=plt.xticks()\n",
    "plt.plot([locs[0]-.5,locs[-1]+.5],[f1_df.loc['Total','f1'],f1_df.loc['Total','f1']],c='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4dd298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full report\n",
    "f1_df[['FP','FN','TP','support']]=f1_df[['FP','FN','TP','support']].applymap('{:.0f}'.format)\n",
    "f1_df['f1_weighted']=f1_df['f1_weighted'].map('{:.2f}%'.format)\n",
    "f1_df['f1']=f1_df['f1'].map('{:.2f}%'.format)\n",
    "\n",
    "f1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0514f5e",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a81d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(y_true,y_pred):\n",
    "\n",
    "    reversed_mapping = {\n",
    "                        0: 'Lead',\n",
    "                        1: 'Position',\n",
    "                        2: 'Evidence',\n",
    "                        3: 'Claim',\n",
    "                        4: 'Concluding_Statement',\n",
    "                        5: 'Counterclaim',\n",
    "                        6: 'Rebuttal',\n",
    "                        7: 'Lead',\n",
    "                        8: 'Position',\n",
    "                        9: 'Evidence',\n",
    "                        10: 'Claim',\n",
    "                        11: 'Concluding_Statement',\n",
    "                        12: 'Counterclaim',\n",
    "                        13: 'Rebuttal',\n",
    "                        14: 'O',\n",
    "                        15: 'PAD'}\n",
    "    \n",
    "    y_true_flat = [reversed_mapping[y] for y in y_true.flatten()]\n",
    "    y_pred_flat = [reversed_mapping[y] for y in y_pred.flatten()]\n",
    "    \n",
    "    LABELS = ['Lead','Position','Claim','Counterclaim','Rebuttal','Evidence','Concluding_Statement','O','PAD']\n",
    "\n",
    "    cfn = confusion_matrix(y_true_flat,y_pred_flat,labels=LABELS)\n",
    "    \n",
    "    fig,ax = plt.subplots(1,1,figsize=(10,10))\n",
    "    plt.title('Confusion Matrix',size=18,pad=20)\n",
    "    sns.heatmap(cfn/np.sum(cfn,axis=0)*100,cmap='Blues',annot = True,fmt='.2f',annot_kws={'size':10},ax=ax);\n",
    "    plt.xticks(np.arange(len(LABELS))+.5,LABELS,rotation = 90,size=12);\n",
    "    plt.yticks(np.arange(len(LABELS))+.5,LABELS,rotation = 0,size=12);\n",
    "    plt.xlabel('PREDICTED',size=16);\n",
    "    plt.ylabel('ACTUAL',size=16);\n",
    "    for t in ax.texts: t.set_text(t.get_text() + \" %\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80189c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_confusion_matrix(y_true,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
